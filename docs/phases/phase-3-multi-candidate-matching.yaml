# phase-3-multi-candidate-matching.yaml
# URL-to-URL Product Matcher - Phase 3 Implementation Guide
# Priority: CRITICAL | Effort: 4 hours | Depends on: Phase 2

meta:
  phase: 3
  name: "Multi-Candidate Matching Engine"
  priority: "CRITICAL"
  effort_hours: 4
  blocking: true
  dependencies: ["phase-1", "phase-2"]

objective: |
  Build the core matching engine that:
  1. Uses pgvector for O(1) similarity search at scale
  2. Returns top 5 candidates per product (not just best match)
  3. Marks products as "No Match" when best score < 50%
  4. Handles 1000 vs 1M scale efficiently

matching_rules:
  exact_match:
    score_range: "95-100%"
    action: "Single best match returned"
    top_candidates: 1

  high_confidence:
    score_range: "90-94%"
    action: "Best match + alternatives"
    top_candidates: 5

  good_match:
    score_range: "80-89%"
    action: "Show top 5 candidates"
    top_candidates: 5

  likely_match:
    score_range: "70-79%"
    action: "Show top 5, mark for review"
    top_candidates: 5
    needs_review: true

  manual_review:
    score_range: "50-69%"
    action: "Show top 5, strongly recommend review"
    top_candidates: 5
    needs_review: true

  no_match:
    score_range: "0-49%"
    action: "Mark as NO MATCH"
    top_candidates: 0
    is_no_match: true

scale_optimization:
  problem: "1000 products × 1M catalog = 1 billion comparisons"
  solution: |
    Phase 1: Generate embeddings for all Site B products (one-time)
    Phase 2: Store embeddings in pgvector with IVFFlat index
    Phase 3: For each Site A product:
      - Generate embedding
      - pgvector similarity search → Top 100 candidates
      - Full multi-signal scoring on 100 candidates
      - Return top 5 matches

  complexity:
    without_optimization: "O(n × m) = 1 billion"
    with_optimization: "O(n × 100) = 100,000"

  cost_comparison:
    without: "$500+ and 10+ hours"
    with: "$5 and 15-30 minutes"

database_migrations:
  - name: "add_top_candidates_column"
    description: "Store top 5 candidates as JSONB"
    sql: |
      ALTER TABLE url_to_url.matches
      ADD COLUMN IF NOT EXISTS top_5_candidates JSONB DEFAULT '[]';

      -- Structure: [
      --   {"product_id": "uuid", "title": "...", "url": "...", "score": 0.82},
      --   {"product_id": "uuid", "title": "...", "url": "...", "score": 0.71},
      --   ...
      -- ]

      COMMENT ON COLUMN url_to_url.matches.top_5_candidates IS
        'Array of top 5 match candidates with scores';

  - name: "add_no_match_columns"
    description: "Track no-match status and reason"
    sql: |
      ALTER TABLE url_to_url.matches
      ADD COLUMN IF NOT EXISTS is_no_match BOOLEAN DEFAULT FALSE;

      ALTER TABLE url_to_url.matches
      ADD COLUMN IF NOT EXISTS no_match_reason TEXT;

      CREATE INDEX IF NOT EXISTS idx_matches_no_match
        ON url_to_url.matches(job_id, is_no_match)
        WHERE is_no_match = true;

  - name: "create_vector_search_function"
    description: "pgvector similarity search RPC"
    sql: |
      CREATE OR REPLACE FUNCTION url_to_url.search_similar_products(
          p_embedding vector(384),
          p_job_id UUID,
          p_site TEXT,
          p_limit INT DEFAULT 100
      ) RETURNS TABLE (
          id UUID,
          title TEXT,
          url TEXT,
          brand TEXT,
          category TEXT,
          similarity FLOAT
      ) AS $$
          SELECT
              id,
              title,
              url,
              brand,
              category,
              1 - (embedding <=> p_embedding) as similarity
          FROM url_to_url.products
          WHERE job_id = p_job_id
            AND site = p_site
            AND embedding IS NOT NULL
          ORDER BY embedding <=> p_embedding
          LIMIT p_limit;
      $$ LANGUAGE SQL STABLE;

  - name: "create_store_match_with_candidates_function"
    description: "Store match with top 5 candidates"
    sql: |
      CREATE OR REPLACE FUNCTION url_to_url.store_match_with_candidates(
          p_job_id UUID,
          p_source_product_id UUID,
          p_matched_product_id UUID,
          p_score DECIMAL,
          p_confidence_tier TEXT,
          p_explanation TEXT,
          p_top_5_candidates JSONB,
          p_is_no_match BOOLEAN DEFAULT FALSE,
          p_no_match_reason TEXT DEFAULT NULL
      ) RETURNS url_to_url.matches AS $$
      DECLARE
          v_result url_to_url.matches;
      BEGIN
          INSERT INTO url_to_url.matches (
              job_id, source_product_id, matched_product_id,
              score, confidence_tier, explanation,
              top_5_candidates, is_no_match, no_match_reason
          ) VALUES (
              p_job_id, p_source_product_id, p_matched_product_id,
              p_score, p_confidence_tier, p_explanation,
              p_top_5_candidates, p_is_no_match, p_no_match_reason
          )
          RETURNING * INTO v_result;

          RETURN v_result;
      END;
      $$ LANGUAGE plpgsql SECURITY DEFINER;

files_to_create:
  - path: "apps/api/services/matcher_v2.py"
    action: "CREATE"
    description: "Multi-candidate matching engine with pgvector"
    code_structure: |
      import logging
      from dataclasses import dataclass, field
      from typing import List, Optional, Dict, Any, Tuple
      from uuid import UUID
      import numpy as np

      from sentence_transformers import SentenceTransformer
      from models.schemas import Product, ConfidenceTier, Site
      from services.supabase import get_supabase_service

      logger = logging.getLogger(__name__)

      @dataclass
      class CandidateMatch:
          product_id: UUID
          title: str
          url: str
          score: float
          brand: str = ""
          category: str = ""

      @dataclass
      class MatchResult:
          source_product: Product
          best_match: Optional[CandidateMatch]
          top_5_candidates: List[CandidateMatch]
          confidence_tier: ConfidenceTier
          explanation: str
          is_no_match: bool
          no_match_reason: str = ""

      class MultiCandidateMatcher:
          """
          Multi-candidate matching engine optimized for scale.
          Uses pgvector for O(1) similarity search.
          """

          SEMANTIC_WEIGHT = 0.60
          TOKEN_WEIGHT = 0.25
          ATTRIBUTE_WEIGHT = 0.15

          NO_MATCH_THRESHOLD = 0.50
          TOP_CANDIDATES = 5
          PRE_FILTER_LIMIT = 100  # pgvector search limit

          def __init__(
              self,
              model_name: str = "sentence-transformers/all-MiniLM-L6-v2"
          ):
              self.model = SentenceTransformer(model_name)
              self.supabase = get_supabase_service()
              logger.info(f"MultiCandidateMatcher initialized with {model_name}")

          def generate_embedding(self, text: str) -> np.ndarray:
              """Generate normalized embedding for text."""
              return self.model.encode(
                  text,
                  normalize_embeddings=True,
                  show_progress_bar=False
              )

          async def generate_embeddings_batch(
              self,
              products: List[Product]
          ) -> Dict[UUID, np.ndarray]:
              """Generate embeddings for multiple products."""
              texts = [p.title for p in products]
              embeddings = self.model.encode(
                  texts,
                  normalize_embeddings=True,
                  show_progress_bar=True,
                  batch_size=32
              )
              return {p.id: emb for p, emb in zip(products, embeddings)}

          async def store_embeddings(
              self,
              job_id: UUID,
              embeddings: Dict[UUID, np.ndarray]
          ) -> int:
              """Store embeddings in database for pgvector search."""
              stored = 0
              for product_id, embedding in embeddings.items():
                  try:
                      # Convert numpy array to list for JSON
                      emb_list = embedding.tolist()
                      await self.supabase.client.rpc('url_store_embedding', {
                          'p_product_id': str(product_id),
                          'p_embedding': emb_list
                      }).execute()
                      stored += 1
                  except Exception as e:
                      logger.error(f"Failed to store embedding for {product_id}: {e}")
              return stored

          async def search_candidates(
              self,
              embedding: np.ndarray,
              job_id: UUID,
              site: Site,
              limit: int = 100
          ) -> List[Tuple[Product, float]]:
              """Use pgvector to find top candidates."""
              result = self.supabase.client.rpc('search_similar_products', {
                  'p_embedding': embedding.tolist(),
                  'p_job_id': str(job_id),
                  'p_site': site.value,
                  'p_limit': limit
              }).execute()

              candidates = []
              for row in result.data or []:
                  product = Product(
                      id=UUID(row['id']),
                      job_id=job_id,
                      site=site,
                      url=row['url'],
                      title=row['title'],
                      brand=row.get('brand'),
                      category=row.get('category')
                  )
                  candidates.append((product, row['similarity']))

              return candidates

          async def match_product(
              self,
              source: Product,
              job_id: UUID,
              target_site: Site = Site.SITE_B
          ) -> MatchResult:
              """
              Match single product against catalog.
              Returns top 5 candidates or NO MATCH.
              """
              # Generate embedding for source product
              source_embedding = self.generate_embedding(source.title)

              # pgvector search for top 100 candidates
              candidates = await self.search_candidates(
                  source_embedding, job_id, target_site, self.PRE_FILTER_LIMIT
              )

              if not candidates:
                  return MatchResult(
                      source_product=source,
                      best_match=None,
                      top_5_candidates=[],
                      confidence_tier=ConfidenceTier.NO_MATCH,
                      explanation="No products found in catalog",
                      is_no_match=True,
                      no_match_reason="Empty catalog"
                  )

              # Multi-signal scoring on candidates
              scored_candidates = []
              for target, semantic_sim in candidates:
                  score = self._compute_multi_signal_score(
                      source, target, semantic_sim
                  )
                  scored_candidates.append(CandidateMatch(
                      product_id=target.id,
                      title=target.title,
                      url=target.url,
                      score=score,
                      brand=target.brand or "",
                      category=target.category or ""
                  ))

              # Sort by score descending
              scored_candidates.sort(key=lambda x: x.score, reverse=True)

              # Apply matching rules
              best = scored_candidates[0]
              top_5 = scored_candidates[:self.TOP_CANDIDATES]

              # Check for NO MATCH
              if best.score < self.NO_MATCH_THRESHOLD:
                  return MatchResult(
                      source_product=source,
                      best_match=None,
                      top_5_candidates=[],
                      confidence_tier=ConfidenceTier.NO_MATCH,
                      explanation=f"Best match scored {best.score:.2%}, below 50% threshold",
                      is_no_match=True,
                      no_match_reason=f"Best candidate: {best.title} ({best.score:.2%})"
                  )

              # Determine confidence tier
              confidence = self._get_confidence_tier(best.score)
              explanation = self._generate_explanation(source, best, confidence)

              return MatchResult(
                  source_product=source,
                  best_match=best,
                  top_5_candidates=top_5,
                  confidence_tier=confidence,
                  explanation=explanation,
                  is_no_match=False
              )

          def _compute_multi_signal_score(
              self,
              source: Product,
              target: Product,
              semantic_sim: float
          ) -> float:
              """Weighted multi-signal scoring."""
              # Semantic similarity (60%)
              semantic_score = semantic_sim * self.SEMANTIC_WEIGHT

              # Token overlap - Jaccard similarity (25%)
              source_tokens = set(source.title.lower().split())
              target_tokens = set(target.title.lower().split())
              intersection = len(source_tokens & target_tokens)
              union = len(source_tokens | target_tokens)
              token_score = (intersection / union if union else 0) * self.TOKEN_WEIGHT

              # Attribute matching (15%)
              attr_score = self._attribute_match(source, target) * self.ATTRIBUTE_WEIGHT

              return semantic_score + token_score + attr_score

          def _attribute_match(self, source: Product, target: Product) -> float:
              """Compare product attributes."""
              score = 0.0
              checks = 0

              if source.brand and target.brand:
                  checks += 1
                  if source.brand.lower() == target.brand.lower():
                      score += 1.0
                  elif source.brand.lower() in target.brand.lower():
                      score += 0.5

              if source.category and target.category:
                  checks += 1
                  if source.category.lower() == target.category.lower():
                      score += 1.0

              return score / checks if checks else 0.0

          def _get_confidence_tier(self, score: float) -> ConfidenceTier:
              """Map score to confidence tier."""
              if score >= 0.95:
                  return ConfidenceTier.EXACT_MATCH
              if score >= 0.90:
                  return ConfidenceTier.HIGH_CONFIDENCE
              if score >= 0.80:
                  return ConfidenceTier.GOOD_MATCH
              if score >= 0.70:
                  return ConfidenceTier.LIKELY_MATCH
              if score >= 0.50:
                  return ConfidenceTier.MANUAL_REVIEW
              return ConfidenceTier.NO_MATCH

          def _generate_explanation(
              self,
              source: Product,
              best: CandidateMatch,
              confidence: ConfidenceTier
          ) -> str:
              """Generate human-readable explanation."""
              if confidence == ConfidenceTier.EXACT_MATCH:
                  return ""

              reasons = []
              if source.brand and best.brand:
                  if source.brand.lower() != best.brand.lower():
                      reasons.append(f"Brand: {source.brand} → {best.brand}")

              if best.score < 0.90:
                  reasons.append(f"Score: {best.score:.0%}")

              return "; ".join(reasons) if reasons else "Minor variations"

  - path: "apps/api/services/job_runner.py"
    action: "CREATE"
    description: "Background job orchestration"
    code_structure: |
      import asyncio
      import logging
      from datetime import datetime
      from uuid import UUID
      from typing import Optional, Callable

      from models.schemas import JobStatus, Site
      from services.supabase import get_supabase_service
      from services.matcher_v2 import MultiCandidateMatcher
      from services.crawler import ProductCrawler

      logger = logging.getLogger(__name__)

      class JobRunner:
          """
          Background job orchestration.
          Handles: Crawl → Embed → Match pipeline.
          """

          def __init__(self):
              self.supabase = get_supabase_service()
              self.matcher = MultiCandidateMatcher()

          async def run_job(
              self,
              job_id: UUID,
              on_progress: Optional[Callable] = None
          ) -> dict:
              """
              Execute full matching pipeline:
              1. Update status to RUNNING
              2. Crawl uncrawled products
              3. Generate embeddings for Site B
              4. Match each Site A product
              5. Store results
              6. Update status to COMPLETED
              """
              try:
                  # 1. Update status
                  await self.supabase.update_job_status(
                      job_id, JobStatus.RUNNING, started_at=datetime.utcnow()
                  )
                  if on_progress:
                      on_progress("started", 0, 0)

                  # 2. Get products
                  site_a_products = await self.supabase.get_products_by_site(
                      job_id, Site.SITE_A
                  )
                  site_b_products = await self.supabase.get_products_by_site(
                      job_id, Site.SITE_B
                  )

                  logger.info(f"Job {job_id}: {len(site_a_products)} source, {len(site_b_products)} target")

                  # 3. Crawl products that need crawling
                  await self._crawl_pending_products(job_id, site_a_products, on_progress)
                  await self._crawl_pending_products(job_id, site_b_products, on_progress)

                  # 4. Generate and store Site B embeddings
                  if on_progress:
                      on_progress("generating_embeddings", 0, len(site_b_products))

                  embeddings = await self.matcher.generate_embeddings_batch(site_b_products)
                  await self.matcher.store_embeddings(job_id, embeddings)

                  # 5. Match each Site A product
                  results = []
                  for i, source in enumerate(site_a_products):
                      if on_progress:
                          on_progress("matching", i + 1, len(site_a_products))

                      result = await self.matcher.match_product(source, job_id)

                      # Store match result
                      await self._store_match_result(job_id, result)
                      results.append(result)

                  # 6. Update status
                  await self.supabase.update_job_status(
                      job_id, JobStatus.COMPLETED, completed_at=datetime.utcnow()
                  )

                  # Calculate stats
                  no_match_count = sum(1 for r in results if r.is_no_match)
                  high_confidence = sum(1 for r in results if not r.is_no_match and r.best_match and r.best_match.score >= 0.80)

                  return {
                      "status": "completed",
                      "total_products": len(site_a_products),
                      "matches_found": len(results) - no_match_count,
                      "no_match": no_match_count,
                      "high_confidence": high_confidence
                  }

              except Exception as e:
                  logger.error(f"Job {job_id} failed: {e}")
                  await self.supabase.update_job_status(job_id, JobStatus.FAILED)
                  raise

          async def _crawl_pending_products(
              self,
              job_id: UUID,
              products: list,
              on_progress: Optional[Callable]
          ):
              """Crawl products that haven't been crawled yet."""
              pending = [p for p in products if p.metadata.get('crawl_status') == 'pending']
              if not pending:
                  return

              async with ProductCrawler() as crawler:
                  for i, product in enumerate(pending):
                      if on_progress:
                          on_progress("crawling", i + 1, len(pending))

                      data = await crawler.crawl_product(product.url)
                      if data.success:
                          # Update product with crawled data
                          await self.supabase.update_product(product.id, {
                              'title': data.title,
                              'brand': data.brand,
                              'category': data.category,
                              'price': data.price,
                              'metadata': {'crawl_status': 'completed', **data.metadata}
                          })

          async def _store_match_result(self, job_id: UUID, result):
              """Store match result in database."""
              # Convert candidates to JSON-serializable format
              candidates_json = [
                  {
                      "product_id": str(c.product_id),
                      "title": c.title,
                      "url": c.url,
                      "score": c.score
                  }
                  for c in result.top_5_candidates
              ]

              await self.supabase.client.rpc('store_match_with_candidates', {
                  'p_job_id': str(job_id),
                  'p_source_product_id': str(result.source_product.id),
                  'p_matched_product_id': str(result.best_match.product_id) if result.best_match else None,
                  'p_score': result.best_match.score if result.best_match else 0,
                  'p_confidence_tier': result.confidence_tier.value,
                  'p_explanation': result.explanation,
                  'p_top_5_candidates': candidates_json,
                  'p_is_no_match': result.is_no_match,
                  'p_no_match_reason': result.no_match_reason
              }).execute()

files_to_modify:
  - path: "apps/api/routers/jobs.py"
    action: "MODIFY"
    changes:
      - name: "add_background_task_run"
        description: "Run job as background task"
        code: |
          from fastapi import BackgroundTasks
          from services.job_runner import JobRunner

          @router.post("/{job_id}/run")
          async def run_job(
              job_id: UUID,
              background_tasks: BackgroundTasks
          ):
              """Start job execution in background."""
              runner = JobRunner()

              # Add to background tasks
              background_tasks.add_task(runner.run_job, job_id)

              return {
                  "status": "started",
                  "message": f"Job {job_id} started in background"
              }

  - path: "apps/web/src/components/MultiMatchCard.tsx"
    action: "CREATE"
    description: "Display top 5 candidates for a match"
    code_structure: |
      interface MultiMatchCardProps {
        sourceProduct: {
          title: string;
          url: string;
          brand?: string;
        };
        topCandidates: Array<{
          product_id: string;
          title: string;
          url: string;
          score: number;
        }>;
        isNoMatch: boolean;
        noMatchReason?: string;
      }

      export function MultiMatchCard({
        sourceProduct,
        topCandidates,
        isNoMatch,
        noMatchReason
      }: MultiMatchCardProps) {
        if (isNoMatch) {
          return (
            <div className="glass-card p-6 border-red-500/30">
              <h3>{sourceProduct.title}</h3>
              <div className="badge-failed">NO MATCH FOUND</div>
              <p className="text-sm text-muted">{noMatchReason}</p>
            </div>
          );
        }

        return (
          <div className="glass-card p-6">
            <h3>{sourceProduct.title}</h3>
            <div className="space-y-2">
              {topCandidates.map((candidate, i) => (
                <div key={candidate.product_id} className="flex items-center gap-4">
                  <span className="badge">{i + 1}</span>
                  <span className="flex-1 truncate">{candidate.title}</span>
                  <span className={`font-mono ${candidate.score >= 0.8 ? 'text-green-500' : 'text-yellow-500'}`}>
                    {(candidate.score * 100).toFixed(0)}%
                  </span>
                  {i === 0 && <span className="badge-completed">Best Match</span>}
                </div>
              ))}
            </div>
          </div>
        );
      }

tests:
  unit:
    - name: "test_pgvector_search"
      description: "Verify similarity search returns correct candidates"

    - name: "test_multi_signal_scoring"
      description: "Verify weighted scoring formula"

    - name: "test_no_match_detection"
      description: "Verify products below 50% marked as no match"

    - name: "test_top_5_selection"
      description: "Verify top 5 candidates returned correctly"

  integration:
    - name: "test_full_matching_pipeline"
      steps:
        - "Create job with 10 Site A, 100 Site B products"
        - "Run job"
        - "Verify each Site A product has match result"
        - "Verify top_5_candidates populated"
        - "Verify is_no_match set correctly"

validation_checklist:
  - "[ ] pgvector search function created"
  - "[ ] matcher_v2.py handles scale efficiently"
  - "[ ] top_5_candidates stored in database"
  - "[ ] is_no_match flag set when score < 50%"
  - "[ ] Background job runs without timeout"
  - "[ ] MultiMatchCard displays candidates"
  - "[ ] 100 products matched in < 2 minutes"

exit_criteria:
  - Run job returns immediately (background)
  - 100 products matched in < 2 minutes
  - Each product has top 5 candidates OR no_match flag
  - Frontend displays all candidates correctly
